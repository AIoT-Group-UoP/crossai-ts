{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Transformers and Pipelines test on DatasetList object\n",
    "\n",
    "In this notebook we check the `caits.transformers` and Sklearn Pipelines consisting of `caits.transformers`."
   ],
   "id": "b5213e6cd83ab3b2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing libraries",
   "id": "8c55223dbc8ed5c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from caits.filtering import filter_butterworth\n",
    "from caits.fe import mean_value, std_value, stft, melspectrogram, istft, central_moments, mfcc_mean\n",
    "from caits.dataset._dataset3 import CoreArray, DatasetList\n",
    "from caits.properties import magnitude_signal\n",
    "from caits.transformers._func_transformer_v2 import FunctionTransformer\n",
    "from caits.transformers._feature_extractor_v2 import FeatureExtractorSignal\n",
    "from caits.transformers._feature_extractor_scalar import FeatureExtractorScalar\n",
    "from caits.transformers._func_transformer_2d_v2 import FunctionTransformer2D\n",
    "from caits.transformers._feature_extractor_2d_v2 import FeatureExtractorSpectrum\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "id": "7219dc2bf1387702",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Dataset loading\n",
    "\n",
    "For this notebook we will use the data/GestureSet_small dataset."
   ],
   "id": "de1622678798cbd6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from caits.loading import csv_loader\n",
    "\n",
    "data = csv_loader(\"data/GestureSet_small\")\n"
   ],
   "id": "648fcb4e67dbae08",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X, y, id = data[\"X\"], data[\"y\"], data[\"id\"]\n",
    "caitsX = [CoreArray(values=x.values, axis_names={\n",
    "    \"axis_1\": {\n",
    "        col: i for i, col in enumerate(x.columns)\n",
    "    }\n",
    "}) for x in X]\n",
    "type(caitsX[0]), type(y[0]), type(id[0])\n"
   ],
   "id": "9c78693960ab7954",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "datasetListObj = DatasetList(caitsX, y, id)\n",
    "datasetListObj"
   ],
   "id": "b04b065448344209",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## FunctionTransformer\n",
    "\n",
    "This transformer is mainly used for transforming the `X` attribute of the `DatasetList` object into a list of `CaitsArray`s with the shape maintained.\n",
    "\n",
    "We test the `caits.transformer.FunctionTransformer` using the `caits.fe.filter_butterworth` function."
   ],
   "id": "2634453b914e9aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "functionTransformer = FunctionTransformer(filter_butterworth, fs=200, filter_type='highpass', cutoff_freq=50)\n",
    "transformedList = functionTransformer.fit_transform(datasetListObj)\n",
    "transformedList"
   ],
   "id": "16c5c962fa53f35b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "datasetListObj.X[0].values",
   "id": "5c3e600656f404a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "transformedList.X[0].values",
   "id": "65270e9da9edddea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## FeatureExtractor\n",
    "\n",
    "This transformer is mainly used for extracting single values per column or per row (if axis=1) for each instance of `DatasetList.X`.\n",
    "\n",
    "We test the `caits.transformer.FeatureExtractor` using the `caits.fe.mean_value` and `caits.fe.std_value`."
   ],
   "id": "9b2b75c4cd0414b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "featureExtractor = FeatureExtractorScalar([\n",
    "    {\n",
    "        \"func\": mean_value,\n",
    "        \"params\": {}\n",
    "    },\n",
    "    {\n",
    "        \"func\": std_value,\n",
    "        \"params\": {\n",
    "            \"ddof\": 0\n",
    "        }\n",
    "    }\n",
    "])\n"
   ],
   "id": "17589aacbd4c8430",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tmp = featureExtractor.fit_transform(datasetListObj)\n",
    "tmp.X"
   ],
   "id": "89da48b5402dc0d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## FeatureExtractor2D\n",
    "\n",
    "This transformer is mainly used for extracting 2D features per column of each instance of `DatasetList.X`.\n",
    "\n",
    "We test this using the `caits.fe.melspectrogram` and `caits.fe.stft`.\n",
    "Applying each of these functions will transform each 2D `CaitsArray` of `DatasetList.X` into a 3D `CaitsArray`."
   ],
   "id": "eca14e5be660340d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "featureExtractor2D = FeatureExtractorSpectrum(melspectrogram, n_fft=10, hop_length=10)\n",
    "tmp = featureExtractor2D.fit_transform(datasetListObj)"
   ],
   "id": "514158463656dcda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tmp.X",
   "id": "2140bf848cc22049",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "featureExtractor2D = FeatureExtractorSpectrum(stft, n_fft=10, hop_length=10)\n",
    "tmp = featureExtractor2D.fit_transform(datasetListObj)"
   ],
   "id": "222e3e5784d7f1d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tmp.X[923].values.shape",
   "id": "bd57a36747a6d407",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## FunctionTransformer2D\n",
    "\n",
    "This is mainly used to inverse the `featureExtractor2D` process. So, if `DatasetList.X` is a list of 3D `CaitsArray` objects, it will be\n",
    "transformed in a list of 2D `CaitsArray`.\n",
    "\n",
    "To test this we use the `caits.fe.istft` on the transformed `DatasetList` object using `caits.fe.stft`."
   ],
   "id": "8dd951b3e0a91fa5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "functionTransformer = FunctionTransformer2D(istft, hop_length=10)\n",
    "tmp = functionTransformer.fit_transform(tmp)"
   ],
   "id": "c8194eb6db47ef43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tmp.X[100].shape, datasetListObj.X[100].shape",
   "id": "ed37d957de83b9b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## SlidingWindow\n",
    "\n",
    "This is used for performing the sliding window process in each instance of the `DatasetList` object.\n",
    "\n",
    "The final windows will be appended in a single `DatasetList` object."
   ],
   "id": "4d4082fd4bfc71ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from caits.transformers._sliding_window_v2 import SlidingWindow\n",
    "\n",
    "slidingWindow = SlidingWindow(window_size=10, overlap=5)\n",
    "tmp = slidingWindow.fit_transform(datasetListObj)"
   ],
   "id": "5dbff9011cae91b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tmp.X[0]",
   "id": "a055bd9265360505",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(tmp.X), len(tmp.y), len(tmp._id)",
   "id": "908cec2dc4245c6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## AugmentSignal\n",
    "\n",
    "This is used for augmenting a `DatasetList` dataset, by processing the instances of the original dataset and appending them to a new `DatasetList` object.\n",
    "This process can be repeated for a number of times, if desired.\n",
    "\n",
    "As a use case, we add white noise and then performing time warping to each instance of the dataset after sliding window is performed. This process\n",
    "is repeated two times, so if our original dataset has `N` instances, the resulting dataset will be consisting of `3*N` instances."
   ],
   "id": "143289fa241b969"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from caits.transformers._augment_singal import AugmentSignal\n",
    "from caits.augmentation import add_noise_ts, time_warp_ts\n",
    "\n",
    "augmentation_transformer = AugmentSignal(\n",
    "    [\n",
    "        {\n",
    "            \"func\": time_warp_ts,\n",
    "            \"params\": {\n",
    "                \"n_speed_change\": 4\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"func\": add_noise_ts,\n",
    "            \"params\": {\n",
    "                \"loc\": 0,\n",
    "                \"scale\": 1,\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    ")\n"
   ],
   "id": "70dbf1d394fa4b58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# augmented_tmp = augmentation_transformer.fit_transform(tmp)",
   "id": "36cde29d70a94f79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# tmp, augmented_tmp\n",
   "id": "581f4428e8410446",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(tmp.X), len(tmp.y), len(tmp._id)\n",
   "id": "48098f9952765895",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# len(augmented_tmp.X), len(augmented_tmp.y), len(augmented_tmp._id)\n",
   "id": "b3db9a11c162d917",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# tmp.X[0], augmented_tmp.X[0]\n",
   "id": "10571889cf4f92b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# augmented_tmp.X[0], augmented_tmp.X[20178]\n",
   "id": "b138de93045a3589",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## DatasetToArray\n",
    "\n",
    "This is used for transforming `DatasetList.X` attribute to a single `np.array`.\n",
    "\n",
    "In this case, each window will be flattened and then all windows will be stacked in a single `np.array`, where each row is a\n",
    "flattened window."
   ],
   "id": "caa48c6e10bf8c92"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from caits.transformers._data_converters_v2 import DatasetToArray\n",
    "\n",
    "dataFlatten = DatasetToArray(flatten=True, dtype=np.float64)\n",
    "\n",
    "dataFlatten.fit(tmp)\n"
   ],
   "id": "e5a5c89465c42e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tmp_conv = dataFlatten.transform(tmp)\n",
    "tmp_conv"
   ],
   "id": "85fe90eb9b3ce1f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tmp_conv.X",
   "id": "5bff86406a49ec24",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ArrayToDataset\n",
    "\n",
    "This is mainly used to transform `DatasetList.X`, which is a single `np.array` in a list of `CaitsArrays` reshaped.\n",
    "\n",
    "In this case we inverse the previous step, taking each flattened window (row of the `CaitsArray) and transforming it\n",
    "in a 2D `CaitsArray`, and then placing them in a list."
   ],
   "id": "a3c522883062e0cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from caits.transformers._data_converters_v2 import ArrayToDataset\n",
    "\n",
    "shape = tmp.X[0].shape\n",
    "\n",
    "dataInverseFlatten = ArrayToDataset(\n",
    "    shape=shape,\n",
    "    dtype=np.float64,\n",
    "    axis_names={\"axis_1\": tmp.X[0].axis_names[\"axis_1\"]}\n",
    ")\n",
    "\n",
    "dataInverseFlatten.fit(tmp_conv)\n",
    "\n",
    "tmp_conv_inv = dataInverseFlatten.transform(tmp_conv)\n"
   ],
   "id": "d7a7955806e8bcd6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tmp_conv_inv.X[0]\n",
   "id": "549824108033c626",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## SklearnWrapper\n",
    "\n",
    "This is mainly used to wrap various `sklearn.transformers` in a way where they internally process a `np.array`, but by\n",
    "always inserting and returning a `DatasetList` object. This is a necessary concept for using `sklearn` capabilities, without\n",
    "losing the structure and attributes of the various `DatasetList` objects.\n",
    "\n",
    "In this case, we test this using `sklearn.preprocesssing.StandardScaler` on the flattened `DatasetList` object."
   ],
   "id": "8c50f49644695c01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from caits.transformers._sklearn_wrapper import SklearnWrapper\n",
    "scaler = SklearnWrapper(StandardScaler)\n",
    "\n",
    "tmp_flat_scaled = scaler.fit_transform(tmp_conv)"
   ],
   "id": "cf9febcee7202340",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "scaler.fitted_transformer_.mean_.shape, scaler.fitted_transformer_.var_.shape",
   "id": "be0ae90beda0fe6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# tmp_flat_scaled.X[0].shape, len(tmp_flat_scaled.y), len(tmp_flat_scaled._id)\n",
    "tmp_flat_scaled.X"
   ],
   "id": "664ee64c3f17261d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Pipelines\n",
    "\n",
    "In this subsection we will test the `sklearn.pipeline.Pipeline` using the `caits.transformer`s.\n",
    "\n"
   ],
   "id": "3d48001b39bf73d0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Use case 1\n",
    "\n",
    "1) the original `DatasetList` object is split into train and test parts\n",
    "2) a pipeline is constructed that performs flattening, standard scaling and unflattening\n",
    "3) the train set is fit in the pipeline and transformed\n",
    "4) the test set is transformed using this pipeline\n"
   ],
   "id": "e663386933bb061f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tmp_train, tmp_test, = tmp.train_test_split(random_state=42)\n",
    "tmp_train, tmp_test, type(tmp_train.X[0]), type(tmp_test.X[0])"
   ],
   "id": "560c9e31630e635b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer, MinMaxScaler\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"conv\", dataFlatten),\n",
    "        (\"scaler\", scaler),\n",
    "        (\"conv_inv\", dataInverseFlatten),\n",
    "    ]\n",
    ")"
   ],
   "id": "cacb21eb63c05e1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pipeline.fit(tmp_train)",
   "id": "d361f832e05cb871",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pipeline.named_steps[\"scaler\"].fitted_transformer_.mean_",
   "id": "b2cf97b165be15c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "final_train = pipeline.fit_transform(tmp_train)\n",
    "final_test = pipeline.transform(tmp_test)"
   ],
   "id": "95ebee4a8fb3e122",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final_train, final_test",
   "id": "b066ffd4be798d65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final_train.X[0].shape, final_test.X[0].shape",
   "id": "79789898305de1b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(final_train.y), len(final_test.y)",
   "id": "b0f7419b29908a91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(pipeline.named_steps['scaler'].fitted_transformer_.mean_.shape)\n",
    "print(pipeline.named_steps['scaler'].fitted_transformer_.var_.shape)\n"
   ],
   "id": "ec6110ed592688fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tmp_train.X[0]",
   "id": "9e589429f66d71a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final_train.X[0]",
   "id": "c37c7948009f8eb8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from caits.visualization import plot_signal\n",
    "\n",
    "plot_signal(tmp_train.X[0].values, return_mode=False)"
   ],
   "id": "1103da5630bd5f82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_signal(final_train.X[0].values, return_mode=False)\n",
   "id": "a2093c2470f9eb3b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_signal(tmp_test.X[0].values, return_mode=False)\n",
   "id": "107ffd8edf5aae8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_signal(final_test.X[0].values, return_mode=False)\n",
   "id": "8dc27759c953af9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Use Case 2\n",
    "\n",
    "1) the original `DatasetList` object is split into train and test parts (already done before)\n",
    "2) a pipeline is constructed that performs flattening, standard scaling and PCA\n",
    "3) the train set is fit in the pipeline and transformed\n",
    "4) the test set is transformed using this pipeline\n"
   ],
   "id": "f76016dc5c572bd9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pipeline2 = Pipeline(\n",
    "    [\n",
    "        (\"conv\", dataFlatten),\n",
    "        (\"scaler\", SklearnWrapper(StandardScaler)),\n",
    "        (\"pca\", SklearnWrapper(PCA, {\"n_components\": 2})),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tmp_pca_train = pipeline2.fit_transform(tmp_train)\n",
    "tmp_pca_test = pipeline2.transform(tmp_test)"
   ],
   "id": "9100e2113e583bcb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tmp_pca_train, tmp_pca_test, tmp_pca_train.X.shape, tmp_pca_test.X.shape",
   "id": "5ebc6a3e21de7fb1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_scatter_pca(\n",
    "        arr: np.ndarray,\n",
    "        c_name: str=\"y\",\n",
    "        cmap_set: str = \"plasma\"\n",
    "\n",
    "):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    if arr.ndim == 2:\n",
    "        plt.style.use('classic')\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        plt.scatter(arr[:, 0], arr[:, 1], c=c_name, cmap=cmap_set)\n",
    "        plt.xlabel('First principal component')\n",
    "        plt.ylabel('Second Principal Component')\n",
    "\n",
    "    elif arr.ndim == 3:\n",
    "        plt.style.use('classic')\n",
    "        fig = plt.figure(figsize=(16, 8))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(arr[:, 0], arr[:, 1], arr[:, 2], c=c_name, cmap=cmap_set)\n",
    "        ax.set_xlabel('First principal component')\n",
    "        ax.set_ylabel('Second Principal Component')\n",
    "        ax.set_zlabel('Third Principal Component')\n",
    "\n",
    "    else:\n",
    "        print(\"The DataFrame has more than 4 columns.\")\n"
   ],
   "id": "2230c81073440803",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_scatter_pca(tmp_pca_train.X.values, cmap_set=\"viridis\")",
   "id": "94aefe5a49dbf4ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_scatter_pca(tmp_pca_test.X.values, cmap_set=\"viridis\")",
   "id": "6113aa45c806d2ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Use Case 3\n",
    "\n",
    "1) the original `DatasetList` object is split into train and test parts (already done before)\n",
    "2) a pipeline is constructed that performs flattening, normalization, quantile transform and unflattening.\n",
    "3) the train set is fit in the pipeline and transformed\n",
    "4) the test set is transformed using this pipeline\n"
   ],
   "id": "65c043c854a69f26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, QuantileTransformer\n",
    "\n",
    "# kwargs_dict = {\n",
    "#     \"output_distribution\": \"uniform\",\n",
    "#     \"n_quantiles\": 100\n",
    "# }\n",
    "\n",
    "pipe_sklearn = Pipeline(\n",
    "    [\n",
    "        (\"flatten\", dataFlatten),\n",
    "        (\"scaler\", SklearnWrapper(MinMaxScaler)),\n",
    "        (\"quantile\", SklearnWrapper(QuantileTransformer, {\"output_distribution\": \"uniform\", \"n_quantiles\": 100})),\n",
    "        # (\"quantile\", SklearnWrapper(QuantileTransformer, **kwargs_dict)),\n",
    "        # (\"pca\", SklearnWrapper(PCA, n_components=2)),\n",
    "        (\"unflatten\", dataInverseFlatten)\n",
    "    ]\n",
    ")"
   ],
   "id": "28457c4ec2e1498e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train = pipe_sklearn.fit_transform(tmp_train)\n",
    "test = pipe_sklearn.transform(tmp_test)"
   ],
   "id": "5ca8f158b6cb000",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_signal(tmp_train.X[0].values, return_mode=False)",
   "id": "10797d60a8064109",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_signal(train.X[0].values, return_mode=False)",
   "id": "1ac03a15df90bff4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_signal(tmp_test.X[0].values, return_mode=False)",
   "id": "d1a1f53dd7afe4c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_signal(test.X[0].values, return_mode=False)",
   "id": "7eafd55a561e3374",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ColumnTransformer",
   "id": "4c916b672da006a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from caits.transformers._column_transformer import ColumnTransformer\n",
    "\n",
    "dataFlatten = DatasetToArray(flatten=True)\n",
    "dataInverseFlattenAcc = ArrayToDataset(shape=(10,3))\n",
    "dataInverseFlattenGyr = ArrayToDataset(shape=(10,3))\n",
    "\n",
    "pipe1 = Pipeline(\n",
    "    [\n",
    "        (\"flatten\", dataFlatten),\n",
    "        (\"scaler\", SklearnWrapper(MinMaxScaler)),\n",
    "        (\"unflatten\", dataInverseFlattenAcc)\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe2 = Pipeline(\n",
    "    [\n",
    "        (\"flatten\", dataFlatten),\n",
    "        (\"scaler\", SklearnWrapper(StandardScaler)),\n",
    "        (\"unflatten\", dataInverseFlattenGyr)\n",
    "    ]\n",
    ")\n",
    "\n",
    "column_tr = ColumnTransformer(\n",
    "    [\n",
    "        (\"acc_pipe\", pipe1, [\"acc_x_axis_g\", \"acc_y_axis_g\", \"acc_z_axis_g\"], [\"new_acc_x\", \"new_acc_y\", \"new_acc_z\"]),\n",
    "        (\"gyr_pipe\", pipe2, [\"gyr_x_axis_deg/s\", \"gyr_y_axis_deg/s\", \"gyr_z_axis_deg/s\"], [\"new_gyr_x\", \"new_gyr_y\", \"new_gyr_z\"])\n",
    "    ],\n",
    "    unify=False\n",
    ")\n"
   ],
   "id": "5c5201787d0f49e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tmp_train.X",
   "id": "bd175ac49deb41e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "column_tr.fit_transform(tmp_train)\n",
   "id": "98e9680f058fbf3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "column_tr.transformations_[0][1].named_steps",
   "id": "910433369c5d8f6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_col_tr = column_tr.transform(tmp_train)\n",
    "train_col_tr, train_col_tr.X[0]"
   ],
   "id": "9cd6c0b92fb9ff9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_col_tr = column_tr.transform(tmp_test)\n",
    "test_col_tr, test_col_tr.X[0]"
   ],
   "id": "126bd414a80a2cc2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Big test",
   "id": "a1b528a269c65e79"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from caits.filtering import filter_median_gen\n",
    "from caits.transformers._func_transformer_v2 import FunctionTransformer\n",
    "from caits.transformers._sklearn_wrapper import SklearnWrapper\n",
    "from caits.transformers._column_transformer import ColumnTransformer\n",
    "\n",
    "pipe_filter = Pipeline(\n",
    "    [\n",
    "        (\"median\", FunctionTransformer(filter_median_gen, window_size=10)),\n",
    "        (\"butterworth\", FunctionTransformer(filter_butterworth, fs=10, filter_type='highpass', cutoff_freq=2))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_scaler = Pipeline(\n",
    "    [\n",
    "        (\"flatten\", DatasetToArray(flatten=True)),\n",
    "        (\"scaler\", SklearnWrapper(StandardScaler)),\n",
    "        (\"unflatten\", ArrayToDataset(shape=(20,3))),\n",
    "    ]\n",
    ")\n",
    "\n",
    "mag_tr = FeatureExtractorSignal(\n",
    "    [\n",
    "        {\n",
    "            \"func\": magnitude_signal,\n",
    "            \"params\": {\n",
    "                \"axis\": 1\n",
    "            }\n",
    "        }\n",
    "    ], axis=1\n",
    ")\n",
    "\n",
    "column_tr1 = ColumnTransformer(\n",
    "    [\n",
    "        (\"filter_acc_x_gyr_x\", pipe_filter, [\"acc_x_axis_g\", \"gyr_x_axis_deg/s\"], [\"new_acc_x\", \"new_gyr_x\"]),\n",
    "        (\"filter_acc_y_gyr_y\", pipe_filter, [\"acc_y_axis_g\", \"gyr_y_axis_deg/s\"], [\"new_acc_y\", \"new_gyr_y\"]),\n",
    "    ],\n",
    "    unify=False\n",
    ")\n",
    "\n",
    "column_tr2 = ColumnTransformer(\n",
    "    [\n",
    "        (\"scale_acc_x_acc_y_acc_z\", pipe_scaler, [\"acc_x_axis_g\", \"acc_y_axis_g\", \"acc_z_axis_g\"], [\"new_acc_x\", \"new_acc_y\", \"new_acc_z\"]),\n",
    "    ],\n",
    "    unify=True\n",
    ")\n",
    "\n",
    "column_tr3 = ColumnTransformer(\n",
    "    [\n",
    "        (\"mag_calc_1\", mag_tr, [\"acc_x_axis_g\", \"acc_y_axis_g\", \"acc_z_axis_g\"], [\"mag_acc\"]),\n",
    "        (\"mag_calc_2\", mag_tr, [\"gyr_x_axis_deg/s\", \"gyr_y_axis_deg/s\", \"gyr_z_axis_deg/s\"], [\"mag_gyr\"]),\n",
    "        (\"mag_calc_3\", mag_tr, [\"new_acc_x\", \"new_acc_y\", \"new_acc_z\"], [\"new_mag_gyr\"]),\n",
    "    ],\n",
    "    unify=True\n",
    ")\n",
    "\n",
    "final_pipe = Pipeline(\n",
    "    [\n",
    "        (\"filter\", column_tr1),\n",
    "        (\"scale\", column_tr2),\n",
    "        (\"mag\", column_tr3),\n",
    "    ]\n",
    ")\n"
   ],
   "id": "25693c4fd813c363",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from caits.transformers._sliding_window_v2 import SlidingWindow\n",
    "\n",
    "sw_transformer = SlidingWindow(window_size=20, overlap=5)\n",
    "sw_data = sw_transformer.fit_transform(datasetListObj)\n",
    "tmp_train, tmp_test = sw_data.train_test_split(test_size=0.2)\n",
    "tmp_train, tmp_test\n"
   ],
   "id": "c2046dc497057fdd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "final_train = final_pipe.fit_transform(tmp_train)\n",
    "final_train.X[0]"
   ],
   "id": "18cd0f557d66ade1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Big test",
   "id": "fc78b6f913c6e26f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from caits.fe import (\n",
    "mean_value,\n",
    "std_value,\n",
    "variance_value,\n",
    "kurtosis_value,\n",
    "dominant_frequency,\n",
    "max_value,\n",
    "average_power,\n",
    "min_value,\n",
    "energy,\n",
    "crest_factor,\n",
    "sample_skewness,\n",
    "delta,\n",
    "rms_max,\n",
    "rms_min,\n",
    "rms_value,\n",
    "rms_mean,\n",
    "zcr_max,\n",
    "zcr_min,\n",
    "zcr_value,\n",
    "zcr_mean,\n",
    "spectral_bandwidth,\n",
    "spectral_std,\n",
    "spectral_kurtosis,\n",
    "spectral_slope,\n",
    "spectral_spread,\n",
    "spectral_rolloff,\n",
    "spectral_skewness,\n",
    "spectral_centroid,\n",
    "spectral_decrease,\n",
    "spectral_flatness,\n",
    "median_value,\n",
    "max_possible_amplitude,\n",
    "central_moments,\n",
    "envelope_energy_peak_detection,\n",
    "spectral_values,\n",
    "underlying_spectral,\n",
    "mfcc_mean,\n",
    ")\n",
    "\n",
    "scalar_tr = FeatureExtractorScalar(\n",
    "    [\n",
    "        {\n",
    "            \"func\": mean_value\n",
    "        },\n",
    "        {\n",
    "            \"func\": std_value\n",
    "        },\n",
    "        {\n",
    "            \"func\": variance_value\n",
    "        },\n",
    "        {\n",
    "            \"func\": kurtosis_value\n",
    "        },\n",
    "        {\n",
    "            \"func\": dominant_frequency,\n",
    "            \"params\": {\n",
    "                \"fs\": 100\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"func\": max_value\n",
    "        },\n",
    "        {\n",
    "            \"func\": crest_factor\n",
    "        },\n",
    "        {\n",
    "            \"func\": min_value\n",
    "        },\n",
    "        {\n",
    "            \"func\": energy\n",
    "        },\n",
    "        {\n",
    "            \"func\": crest_factor\n",
    "        },\n",
    "        {\n",
    "            \"func\": average_power\n",
    "        },\n",
    "        {\n",
    "            \"func\": sample_skewness\n",
    "        },\n",
    "        {\n",
    "            \"func\": rms_mean,\n",
    "            \"params\": {\n",
    "                \"frame_length\": 20,\n",
    "                \"hop_length\": 10\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"func\": rms_value,\n",
    "        },\n",
    "        {\n",
    "            \"func\": rms_max,\n",
    "            \"params\": {\n",
    "                \"frame_length\": 20,\n",
    "                \"hop_length\": 10\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"func\": rms_min,\n",
    "            \"params\": {\n",
    "                \"frame_length\": 20,\n",
    "                \"hop_length\": 10\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"func\": zcr_value\n",
    "        },\n",
    "        {\n",
    "            \"func\": zcr_max,\n",
    "            \"params\": {\n",
    "                \"frame_length\": 20,\n",
    "                \"hop_length\": 10\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"func\": zcr_min,\n",
    "            \"params\": {\n",
    "                \"frame_length\": 20,\n",
    "                \"hop_length\": 10\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"func\": zcr_mean,\n",
    "            \"params\": {\n",
    "                \"frame_length\": 20,\n",
    "                \"hop_length\": 10\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"func\": spectral_bandwidth,\n",
    "            \"params\": {\n",
    "                \"fs\": 100\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"func\": spectral_std,\n",
    "            \"params\": {\n",
    "                \"fs\": 100\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"func\": spectral_kurtosis,\n",
    "            \"params\": {\n",
    "                \"fs\": 100\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"func\": spectral_slope,\n",
    "            \"params\": {\n",
    "                \"fs\": 100\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"func\": spectral_rolloff,\n",
    "            \"params\": {\n",
    "                \"fs\": 100\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"func\": spectral_skewness,\n",
    "            \"params\": {\n",
    "                \"fs\": 100\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"func\": spectral_centroid,\n",
    "            \"params\": {\n",
    "                \"fs\": 100\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"func\": spectral_decrease,\n",
    "            \"params\": {\n",
    "                \"fs\": 100\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"func\": spectral_flatness,\n",
    "            \"params\": {\n",
    "                \"fs\": 100\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"func\": median_value,\n",
    "        },\n",
    "        {\n",
    "            \"func\": central_moments\n",
    "        },\n",
    "        {\n",
    "            \"func\": max_possible_amplitude\n",
    "\n",
    "        },\n",
    "        {\n",
    "            \"func\": delta,\n",
    "        },\n",
    "        {\n",
    "            \"func\": spectral_spread,\n",
    "            \"params\": {\n",
    "                \"fs\": 100\n",
    "            }\n",
    "        },\n",
    "    ]\n",
    ")"
   ],
   "id": "f204f45fd8f2ed81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "scaled_data = scalar_tr.fit_transform(sw_data)",
   "id": "2fc6373692e3206b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "scaled_data.X[0]",
   "id": "9c8cc9e938f2bb8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "scaled = scaled_data.to_numpy(flatten=True)\n",
    "scaled"
   ],
   "id": "ad660c8de8359daf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "scaled[0].shape",
   "id": "775daed39ce1915f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "flat_scaled = scaled_data.flatten()\n",
    "flat_scaled"
   ],
   "id": "80ec7dea77b5024c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "flat_scaled.X",
   "id": "dd34a437ba9bfed5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
